{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1 - High Level Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_prep import get_img_df, train_val_test_split\n",
    "from image_gen import get_gen_from_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_path = \"data/Food_Classification/\"\n",
    "\n",
    "# get df\n",
    "df_fc = get_img_df(fc_path)\n",
    "\n",
    "num_classes = len(df_fc['label'].unique())\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dfs\n",
    "train, validate, test = train_val_test_split(df_fc, test_size=0.2, val_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = get_gen_from_df(train)\n",
    "validate_gen = get_gen_from_df(validate, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model is probably not the final model we want to use but just needed something to test and end to end flow.  \n",
    "\n",
    "This particular architecture was borrowed from the Jupyter notebook found: https://www.kaggle.com/code/varsha300/transferlearning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = (224, 224)  # VGG16 default image size\n",
    "\n",
    "# model\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)))\n",
    "# Freeze base model layers and unfreeze the last 4 layers\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Model architecture\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit(train_gen, validation_data=validate_gen, epochs=1, steps_per_epoch=train_gen.num_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(validate_gen)\n",
    "print(f'Validation accuracy: {val_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2 - Find Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4060 Laptop GPU, compute capability 8.9\n"
     ]
    }
   ],
   "source": [
    "import cv_models \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from image_prep import get_split_data\n",
    "df_train, df_validate, df_test = get_split_data()\n",
    "train_gen, validate_gen = cv_models.get_training_data(df_train, df_validate, batch_size=32)\n",
    "\n",
    "type(train_gen)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Training: Model_Xception__Dropout_0.2__HiddenSize_500**********\n",
      "\n",
      "Found 3760 validated image filenames belonging to 20 classes.\n",
      "Found 1255 validated image filenames belonging to 20 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\preprocessing\\image.py:1139: UserWarning: Found 2 invalid image filename(s) in x_col=\"path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "117/117 [==============================] - 117s 974ms/step - loss: 7.9971 - accuracy: 0.0695 - val_loss: 8.8635 - val_accuracy: 0.0913\n",
      "Epoch 2/5\n",
      "117/117 [==============================] - 119s 1s/step - loss: 8.0787 - accuracy: 0.1062 - val_loss: 7.9392 - val_accuracy: 0.1178\n",
      "Epoch 3/5\n",
      "117/117 [==============================] - 116s 992ms/step - loss: 7.8204 - accuracy: 0.0974 - val_loss: 6.6486 - val_accuracy: 0.0745\n",
      "Epoch 4/5\n",
      "117/117 [==============================] - 113s 966ms/step - loss: 7.7928 - accuracy: 0.0885 - val_loss: 7.5460 - val_accuracy: 0.0553\n",
      "Epoch 5/5\n",
      "117/117 [==============================] - 115s 982ms/step - loss: 7.8676 - accuracy: 0.0612 - val_loss: 7.7248 - val_accuracy: 0.0737\n",
      "40/40 [==============================] - 26s 639ms/step - loss: 7.7490 - accuracy: 0.0741\n",
      "Validation accuracy: 7.41%\n",
      "Best Accuracy: 0.07410358637571335\n",
      "Best validation set: Model_Xception__Dropout_0.2__HiddenSize_500\n",
      "**********\n",
      "Training: Model_Xception__Dropout_0.2__HiddenSize_600**********\n",
      "\n",
      "Found 3760 validated image filenames belonging to 20 classes.\n",
      "Found 1255 validated image filenames belonging to 20 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\preprocessing\\image.py:1139: UserWarning: Found 2 invalid image filename(s) in x_col=\"path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "117/117 [==============================] - 116s 976ms/step - loss: 7.9379 - accuracy: 0.0840 - val_loss: 8.3504 - val_accuracy: 0.0697\n",
      "Epoch 2/5\n",
      "117/117 [==============================] - 115s 984ms/step - loss: 8.0164 - accuracy: 0.0998 - val_loss: 7.9142 - val_accuracy: 0.0946\n",
      "Epoch 3/5\n",
      "117/117 [==============================] - 114s 974ms/step - loss: 7.9094 - accuracy: 0.0805 - val_loss: 8.2673 - val_accuracy: 0.0938\n",
      "Epoch 4/5\n",
      "117/117 [==============================] - 115s 987ms/step - loss: 8.0824 - accuracy: 0.0891 - val_loss: 8.3780 - val_accuracy: 0.1066\n",
      "Epoch 5/5\n",
      "117/117 [==============================] - 115s 980ms/step - loss: 7.7860 - accuracy: 0.0848 - val_loss: 7.5239 - val_accuracy: 0.1130\n",
      "40/40 [==============================] - 26s 618ms/step - loss: 7.5472 - accuracy: 0.1124\n",
      "Validation accuracy: 11.24%\n",
      "Best Accuracy: 0.11235059797763824\n",
      "Best validation set: Model_Xception__Dropout_0.2__HiddenSize_600\n",
      "**********\n",
      "Training: Model_Xception__Dropout_0.2__HiddenSize_800**********\n",
      "\n",
      "Found 3760 validated image filenames belonging to 20 classes.\n",
      "Found 1255 validated image filenames belonging to 20 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\preprocessing\\image.py:1139: UserWarning: Found 2 invalid image filename(s) in x_col=\"path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "117/117 [==============================] - 118s 993ms/step - loss: 7.6744 - accuracy: 0.1025 - val_loss: 7.6173 - val_accuracy: 0.1731\n",
      "Epoch 2/5\n",
      "117/117 [==============================] - 115s 986ms/step - loss: 7.9561 - accuracy: 0.1062 - val_loss: 8.0239 - val_accuracy: 0.0921\n",
      "Epoch 3/5\n",
      "117/117 [==============================] - 115s 983ms/step - loss: 7.7978 - accuracy: 0.0955 - val_loss: 8.1924 - val_accuracy: 0.1258\n",
      "Epoch 4/5\n",
      "117/117 [==============================] - 116s 993ms/step - loss: 7.8217 - accuracy: 0.0810 - val_loss: 7.4915 - val_accuracy: 0.0585\n",
      "Epoch 5/5\n",
      "117/117 [==============================] - 116s 993ms/step - loss: 7.9208 - accuracy: 0.0574 - val_loss: 8.7295 - val_accuracy: 0.0801\n",
      "40/40 [==============================] - 26s 653ms/step - loss: 8.7476 - accuracy: 0.0805\n",
      "Validation accuracy: 8.05%\n",
      "**********\n",
      "Training: Model_Xception__Dropout_0.2__HiddenSize_1000**********\n",
      "\n",
      "Found 3760 validated image filenames belonging to 20 classes.\n",
      "Found 1255 validated image filenames belonging to 20 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\preprocessing\\image.py:1139: UserWarning: Found 2 invalid image filename(s) in x_col=\"path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'tasty_model_3/xception/block1_conv2/Conv2D' defined at (most recent call last):\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Jon\\AppData\\Local\\Temp\\ipykernel_24532\\3709424155.py\", line 11, in <module>\n      for best_acc, best_model_name, best_dropout, best_hidden, all_results in cv_models.find_best_model(5):\n    File \"c:\\Users\\Jon\\Documents\\UMSI\\Courses\\dev\\Capstone\\indian-food\\cv_models.py\", line 123, in find_best_model\n      history, model, val_loss, val_accuracy = train_transfer_model(\n    File \"c:\\Users\\Jon\\Documents\\UMSI\\Courses\\dev\\Capstone\\indian-food\\cv_models.py\", line 100, in train_transfer_model\n      history = model.fit(train_gen, validation_data=validate_gen, epochs=epochs,\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\Documents\\UMSI\\Courses\\dev\\Capstone\\indian-food\\cv_models.py\", line 45, in call\n      x = self.base_model(inputs, training=False)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'tasty_model_3/xception/block1_conv2/Conv2D'\nOOM when allocating tensor with shape[64,3,3,32] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node tasty_model_3/xception/block1_conv2/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_138707]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mBest Accuracy: 0.13067729771137238\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mBest validation set: Model_Xception__Dropout_0.3__HiddenSize_200\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mBest validation set: Model_Xception__Dropout_0.2__HiddenSize_500\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# store results in each run in case of exception\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m best_acc, best_model_name, best_dropout, best_hidden, all_results \u001b[38;5;129;01min\u001b[39;00m cv_models\u001b[38;5;241m.\u001b[39mfind_best_model(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jon\\Documents\\UMSI\\Courses\\dev\\Capstone\\indian-food\\cv_models.py:123\u001b[0m, in \u001b[0;36mfind_best_model\u001b[1;34m(epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__Dropout_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__HiddenSize_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**********\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvals\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m**********\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 123\u001b[0m history, model, val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_transfer_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_validate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# free up model memory\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m(model)\n",
      "File \u001b[1;32mc:\\Users\\Jon\\Documents\\UMSI\\Courses\\dev\\Capstone\\indian-food\\cv_models.py:100\u001b[0m, in \u001b[0;36mtrain_transfer_model\u001b[1;34m(base_model, df_train, df_validate, epochs, num_classes, hidden_size, dropout, batch_size)\u001b[0m\n\u001b[0;32m     97\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m),\n\u001b[0;32m     98\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(validate_gen)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'tasty_model_3/xception/block1_conv2/Conv2D' defined at (most recent call last):\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Jon\\AppData\\Local\\Temp\\ipykernel_24532\\3709424155.py\", line 11, in <module>\n      for best_acc, best_model_name, best_dropout, best_hidden, all_results in cv_models.find_best_model(5):\n    File \"c:\\Users\\Jon\\Documents\\UMSI\\Courses\\dev\\Capstone\\indian-food\\cv_models.py\", line 123, in find_best_model\n      history, model, val_loss, val_accuracy = train_transfer_model(\n    File \"c:\\Users\\Jon\\Documents\\UMSI\\Courses\\dev\\Capstone\\indian-food\\cv_models.py\", line 100, in train_transfer_model\n      history = model.fit(train_gen, validation_data=validate_gen, epochs=epochs,\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\Documents\\UMSI\\Courses\\dev\\Capstone\\indian-food\\cv_models.py\", line 45, in call\n      x = self.base_model(inputs, training=False)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Users\\Jon\\miniconda3\\envs\\Tasty_AI\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'tasty_model_3/xception/block1_conv2/Conv2D'\nOOM when allocating tensor with shape[64,3,3,32] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node tasty_model_3/xception/block1_conv2/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_138707]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Accuracy: 0.13067729771137238\n",
    "Best validation set: Model_Xception__Dropout_0.3__HiddenSize_200\n",
    "\n",
    "Validation accuracy: 13.78%\n",
    "Best Accuracy: 0.1378486007452011\n",
    "Best validation set: Model_Xception__Dropout_0.2__HiddenSize_500\n",
    "\"\"\"\n",
    "\n",
    "# store results in each run in case of exception\n",
    "for best_acc, best_model_name, best_dropout, best_hidden, all_results in cv_models.find_best_model(5, batch_size=16):\n",
    "    continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"TensorFlow is using GPU\")\n",
    "    for gpu in gpus:\n",
    "        print(\"GPU:\", gpu.name)\n",
    "else:\n",
    "    print(\"TensorFlow is not using GPU\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tasty_AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
