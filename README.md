# Tasty_AI
### Description
1. Use multiclass image classification to identify Indian food dishes
2. Based on predicted label and other inputs, recommend recipes and similar dishes
3. Refine recommendations via reinforcement learning

### Setup
Install environment from conda file
```
conda env create -f environment.yml
```

Then activate
```
conda activate Tasty_AI
```

## Application

The application is a streamlit application.  To run, execute the following command:
```
streamlit run tastyai_ui.py
```


### Data Sources

**Data Access**
All external data sources are open datasets, found on Kaggle.

**Food_Classification**
* https://www.kaggle.com/datasets/l33tc0d3r/indian-food-classification?resource=download-directory

**Recipe data**
 * https://www.kaggle.com/code/cardata/indian-food-cuisine-data-analysis/input
 * https://www.kaggle.com/code/amankumar2002/image-to-recipe/input


### Modules 
Here are the modules used to run the application 

| Application Area | File | Description |
| --- | --- |--- |
|Recommendation Engine|recommendation_models.py|** TBD **|
|Recommendation Engine|save_load_recommendation_models_vectorizers.py|** TBD **|
|Image Classification|cv_model.py|Define the computer vision model|
|Image Classification|cv_predict.py|Wrapper class to simplify classification predictions|
|Image Classification| image_prep.py | Tools for retriving image files and converting to pandas dataframe |
|Image Classification| image_gen.py | Tools for converting dataframes to keras image generators |
|Reinforcement Learning|save_user_feedback.py|** TBD **|
|Reinforcement Learning|feedback_reinf_learn_recommendation_model.py|** TBD **|
|Web Application|Dockerfile|Define what goes into the docker container|
|Web Application|.dockerignore|Define what *doesn't* goes into the docker container|
|Web Application|tastyai_ui.py|Streamlit application file.  This file primarily defines the view|
|Web Application|ui_functions.py|Separation of concerns for streamlit application.  This file contains the logical/controller aspects of the web application.|
|Repository Management|.gitignore|Specify files to exclude from adding to git|
|Environment Management|envrionment.yml|Conda environment file to ensure all packages are available|



### Jupyter Notebooks (Examples)
In addition to the modules, it can be helpful to have a variety of examples to have a detailed view as to why certain technical decisions were made.

| Application Area | File | Description |
| --- | --- |--- |
|Image Classification| Example_CV1_Train._Classifier.ipynb | Train and evaluate image classifier model |
|Recommendation Engine|example_compare_recommendation_models.ipynb|** TBD **|
|Recommendation Engine|prepare_recommendation_data.ipynb|** TBD **|
|Recommendation Engine|topic_modeling_NMF.ipynb|** TBD **|
|Recommendation Engine|topic_modeling_SVD.ipynb|** TBD **|


### Working Data
There are two categories of persisted data: 
* Source Data - this is data that is downloaded from the data sources listed above
* Model Data - this is data has been constructed and serialized for future use

#### Source Data
| Usage | Path |
| --- | --- |
|Image classifier training data| data/Food_Classification|


#### Model Data
Note: This data may not actually exist as it is too large to check into GitHub.  Instead, it will be generated by running the code in the notebooks.  The status column will let the reader know if it exists in GitHub or needs to be generated by running the code.

| Usage | Status | Path |
| --- | --- | --- |
|Image classifier weights| Generated | models/weights/efficientnet_v2_20_84.64.hdf5|
|Image classifier - TF Lite model| Generated | models/lite/efficientnet_v2_20_84.64.tflite|
|Recomendation Count Vectorizer| Checked in | models/count_vectorizer.pkl|
|Recomendation NMF Count Model|Checked in | models/nmf_count_model.pkl|
|Recomendation NMF TF-IDF Model|Checked in | models/nmf_count_model.pkl|
|Recomendation Vectorizer Count Model|Checked in | models/tfidf_vectorizer.pkl|
|Recomendation Vectorizer TF-IDF Model|Checked in | models/tfidf_vectorizer.pkl|




